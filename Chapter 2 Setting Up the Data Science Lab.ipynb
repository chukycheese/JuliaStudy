{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19020×11 Array{Any,2}:\n",
       "  28.7967   16.0021  2.6449  0.3918  …   -8.2027  40.092    81.8828  \"g\"\n",
       "  31.6036   11.7235  2.5185  0.5303      -9.9574   6.3609  205.261   \"g\"\n",
       " 162.052   136.031   4.0612  0.0374     -45.216   76.96    256.788   \"g\"\n",
       "  23.8172    9.5728  2.3385  0.6147      -7.1513  10.449   116.737   \"g\"\n",
       "  75.1362   30.9205  3.1611  0.3168      21.8393   4.648   356.462   \"g\"\n",
       "  51.624    21.1502  2.9085  0.242   …    9.8145   3.613   238.098   \"g\"\n",
       "  48.2468   17.3565  3.0332  0.2529      10.5868   4.792   219.087   \"g\"\n",
       "  26.7897   13.7595  2.5521  0.4236      -2.9292   0.812   237.134   \"g\"\n",
       "  96.2327   46.5165  4.154   0.0779      43.1844   4.854   248.226   \"g\"\n",
       "  46.7619   15.1993  2.5786  0.3377      -6.6812   7.875   102.251   \"g\"\n",
       "  62.7766   29.9104  3.3331  0.2475  …   23.771    9.9144  323.094   \"g\"\n",
       "  18.8562   16.46    2.4385  0.5282     -16.9327  11.461   162.848   \"g\"\n",
       "  45.6321   22.71    3.0441  0.2213     -14.3164   0.3822  178.255   \"g\"\n",
       "   ⋮                                 ⋱                               ⋮  \n",
       " 133.495    40.1631  3.305   0.1169     -31.0503  28.1458  319.373   \"h\"\n",
       "  39.5223   18.6327  2.8341  0.2462     -12.9245  46.268   187.097   \"h\"\n",
       "  32.4902   10.6723  2.4742  0.4664  …    8.4813  69.173   120.668   \"h\"\n",
       "  79.5528   44.9929  3.5488  0.1656     -30.0054  15.8075  311.568   \"h\"\n",
       "  31.8373   13.8734  2.8251  0.4169      11.1098  11.3663  100.057   \"h\"\n",
       " 182.5      76.5568  3.6872  0.1123     -62.6192  82.1691  283.473   \"h\"\n",
       "  43.298    17.3545  2.8307  0.2877      -3.6545  78.4099  224.83    \"h\"\n",
       "  21.3846   10.917   2.6161  0.5857  …    2.8766   2.4229  106.826   \"h\"\n",
       "  28.9452    6.702   2.2672  0.5351      -2.9632  86.7975  247.456   \"h\"\n",
       "  75.4455   47.5305  3.4483  0.1417      -9.4662  30.2987  256.517   \"h\"\n",
       " 120.513    76.9018  3.9939  0.0944     -63.8389  84.6874  408.317   \"h\"\n",
       " 187.181    53.0014  3.2093  0.2876      31.4755  52.731   272.317   \"h\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd(\"C:/dev/julia/JuliaStudy\")\n",
    "pwd()\n",
    "\n",
    "# Loading Datasets\n",
    "# CSV files\n",
    "data = readcsv(\".\\\\Data files-selected\\\\Magic\\\\magic04.csv\")\n",
    "\n",
    "# # Text files\n",
    "# f = open(filename, \"r\")\n",
    "# lines = readlines(f)\n",
    "# close(f)\n",
    "\n",
    "# f = open(filename, \"r\")\n",
    "# for line in eachline(f)\n",
    "#   [some code]\n",
    "\n",
    "# end\n",
    "# close(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "distance (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p.32 Coding and testing a simple machine learning algorithm in Julia\n",
    "# Algorithm implemetation\n",
    "# Listing 2.2 An auxilirary function for the impementation of the kNN algorithm.\n",
    "# This one is responsible for calculating the distance between two points, x and y, represented as vectors.\n",
    "function distance{T<:Number}(x::Array{T, 1}, y::Array{T, 1})\n",
    "  dist = 0              # A\n",
    "  for i in 1:length(x)  # B\n",
    "    dist += (x[i] - y[i])^2\n",
    "  end\n",
    "  dist = sqrt(dist)\n",
    "  return dist\n",
    "end\n",
    "# A: initializedistance variable\n",
    "# B: repeat for all dimensions of x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Base.Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7320508075688772"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1, 2, 3]\n",
    "y = [2, 3, 4]\n",
    "distance(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: isapprox\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "isapprox(x, y; rtol::Real=sqrt(eps), atol::Real=0)\n",
       "```\n",
       "\n",
       "Inexact equality comparison: `true` if `norm(x-y) <= atol + rtol*max(norm(x), norm(y))`. The default `atol` is zero and the default `rtol` depends on the types of `x` and `y`.\n",
       "\n",
       "For real or complex floating-point values, `rtol` defaults to `sqrt(eps(typeof(real(x-y))))`. This corresponds to requiring equality of about half of the significand digits. For other types, `rtol` defaults to zero.\n",
       "\n",
       "`x` and `y` may also be arrays of numbers, in which case `norm` defaults to `vecnorm` but may be changed by passing a `norm::Function` keyword argument. (For numbers, `norm` is the same thing as `abs`.) When `x` and `y` are arrays, if `norm(x-y)` is not finite (i.e. `±Inf` or `NaN`), the comparison falls back to checking whether all elements of `x` and `y` are approximately equal component-wise.\n",
       "\n",
       "The binary operator `≈` is equivalent to `isapprox` with the default arguments, and `x ≉ y` is equivalent to `!isapprox(x,y)`.\n"
      ],
      "text/plain": [
       "```\n",
       "isapprox(x, y; rtol::Real=sqrt(eps), atol::Real=0)\n",
       "```\n",
       "\n",
       "Inexact equality comparison: `true` if `norm(x-y) <= atol + rtol*max(norm(x), norm(y))`. The default `atol` is zero and the default `rtol` depends on the types of `x` and `y`.\n",
       "\n",
       "For real or complex floating-point values, `rtol` defaults to `sqrt(eps(typeof(real(x-y))))`. This corresponds to requiring equality of about half of the significand digits. For other types, `rtol` defaults to zero.\n",
       "\n",
       "`x` and `y` may also be arrays of numbers, in which case `norm` defaults to `vecnorm` but may be changed by passing a `norm::Function` keyword argument. (For numbers, `norm` is the same thing as `abs`.) When `x` and `y` are arrays, if `norm(x-y)` is not finite (i.e. `±Inf` or `NaN`), the comparison falls back to checking whether all elements of `x` and `y` are approximately equal component-wise.\n",
       "\n",
       "The binary operator `≈` is equivalent to `isapprox` with the default arguments, and `x ≉ y` is equivalent to `!isapprox(x,y)`.\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?isapprox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isapprox(distance(x, y), 1.7320508075688772)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Test Passed\n",
       "  Expression: distance(x,y) ≈ 1.7320508075688772\n",
       "   Evaluated: 1.7320508075688772 isapprox 1.7320508075688772"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test distance(x, y) ≈ 1.7320508075688772    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classify (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listing 2.3 Another auxiliary function of the implementation of the kNN algorithm\n",
    "# This one performs classification of a point based on tis distances from the known points of the dataset.\n",
    "function classify{T<:Any}(distances::Array{Float64, 1}, labels::Array{T, 1}, k::Int)\n",
    "        class = unique(labels)                  # A\n",
    "        nc = length(class)                      # B\n",
    "        indexes = Array(Int, k)                 # C\n",
    "        M = typemax(typeof(distances[1]))       # D\n",
    "        class_count = Array(Int, nc)\n",
    "        for i in 1:k\n",
    "                indexes[i] = indmin(distances)\n",
    "                distances[indexes[i]] = M       # E\n",
    "        end\n",
    "        klabels = labels[indexes]\n",
    "\n",
    "        for i in 1:nc\n",
    "                for j in 1:k\n",
    "                        if klabels[j] == class[i]\n",
    "                                class_count[i] += 1\n",
    "                                break\n",
    "                        end\n",
    "                end\n",
    "        end\n",
    "        index = indmax(class_count)\n",
    "        return class[index]\n",
    "end\n",
    "# A: find all the distinct classes\n",
    "# B: number of classes\n",
    "# C: initialize vector of indexes of the nearest neighbors\n",
    "# D: the largest possible number that this vector can have\n",
    "# E: make sure this element is not selected again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: X not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: X not defined",
      ""
     ]
    }
   ],
   "source": [
    "N = size(X, 1)                          # A\n",
    "n = size(Y, 1)                          # B\n",
    "D = Array(Float64, N)                   # C\n",
    "z = Array(typeof(x[1]), n)              # D\n",
    "for i in 1:n\n",
    "                for j in 1:N\n",
    "                        D[j] = distance(X[j, :], Y[i, :])\n",
    "                end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 268.359\n",
       " 248.875\n",
       " 239.59 \n",
       " 204.249"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Test Passed\n",
       "  Expression: classify(D,x,4) == \"h\"\n",
       "   Evaluated: \"h\" == \"h\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test classify(D, x, 1) == \"g\"\n",
    "@test classify(D, x, 2) == \"g\"\n",
    "@test classify(D, x, 3) == \"g\"\n",
    "@test classify(D, x, 4) == \"h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition "
     ]
    },
    {
     "data": {
      "text/plain": [
       "apply_kNN (generic function with 1 method)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "apply_kNN(Array{#T1<:Number, 2}, Array{#T2<:Any, 1}, Array{#T1<:Number, 2}, Int64) in module Main at In[30]:3 overwritten at In[90]:3.\n"
     ]
    }
   ],
   "source": [
    "# Listing 2.4 The main function(wrapper) of the implementation of the kNN algorithm.\n",
    "function apply_kNN{T1<:Number, T2<:Any}(X::Array{T1, 2}, x::Array{T2, 1}, Y::Array{T1, 2}, k::Int)\n",
    "        N = size(X, 1)                          # A\n",
    "        n = size(Y, 1)                          # B\n",
    "        D = Array(Float64, N)                   # C\n",
    "        z = Array(typeof(x[1]), n)              # D\n",
    "        for i in 1:n\n",
    "                for j in 1:N\n",
    "                        D[j] = distance(X[j, :], Y[i, :])\n",
    "                end\n",
    "                z[i] = classify(D, x, k)\n",
    "        end\n",
    "        return z\n",
    "end\n",
    "\n",
    "# A: number of known data points\n",
    "# B: number of data points to classify\n",
    "# C: initialize distance vector\n",
    "# D: initialize labels vector (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Failed\n",
      "  Expression: string.(apply_kNN(X,x,Y,1)) == [\"h\",\"g\",\"g\",\"g\"]\n",
      "   Evaluated: SubString{String}[\"h\",\"g\",\"h\",\"g\"] == String[\"h\",\"g\",\"g\",\"g\"]\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "LoadError: There was an error during testing\nwhile loading In[87], in expression starting on line 1",
     "output_type": "error",
     "traceback": [
      "LoadError: There was an error during testing\nwhile loading In[87], in expression starting on line 1",
      "",
      " in record(::Base.Test.FallbackTestSet, ::Base.Test.Fail) at .\\test.jl:397",
      " in do_test(::Base.Test.Returned, ::Expr) at .\\test.jl:281"
     ]
    }
   ],
   "source": [
    "@test string.(apply_kNN(X, x, Y, 1)) == [\"h\", \"g\", \"g\", \"g\"]\n",
    "@test string.(apply_kNN(X, x, Y, 2)) == [\"g\", \"g\", \"g\", \"g\"]\n",
    "@test string.(apply_kNN(X, x, Y, 3)) == [\"h\", \"h\", \"g\", \"h\"]\n",
    "@test string.(apply_kNN(X, x, Y, 4)) == [\"g\", \"g\", \"g\", \"h\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×11 Array{Any,2}:\n",
       "  75.4455  47.5305  3.4483  0.1417  …   -9.4662  30.2987  256.517  \"h\"\n",
       " 120.513   76.9018  3.9939  0.0944     -63.8389  84.6874  408.317  \"h\"\n",
       " 187.181   53.0014  3.2093  0.2876      31.4755  52.731   272.317  \"h\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_g = magic_data[1:5, :]\n",
    "data_h = magic_data[end-2:end, :]\n",
    "\n",
    "data = vcat(data_g, data_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×11 Array{Any,2}:\n",
       "  28.7967   16.0021  2.6449  0.3918  …   -8.2027  40.092    81.8828  \"g\"\n",
       "  31.6036   11.7235  2.5185  0.5303      -9.9574   6.3609  205.261   \"g\"\n",
       " 162.052   136.031   4.0612  0.0374     -45.216   76.96    256.788   \"g\"\n",
       "  23.8172    9.5728  2.3385  0.6147      -7.1513  10.449   116.737   \"g\"\n",
       "  75.1362   30.9205  3.1611  0.3168      21.8393   4.648   356.462   \"g\"\n",
       "  75.4455   47.5305  3.4483  0.1417  …   -9.4662  30.2987  256.517   \"h\"\n",
       " 120.513    76.9018  3.9939  0.0944     -63.8389  84.6874  408.317   \"h\"\n",
       " 187.181    53.0014  3.2093  0.2876      31.4755  52.731   272.317   \"h\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{SubString{String},1}:\n",
       " \"h\"\n",
       " \"h\"\n",
       " \"h\"\n",
       " \"h\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p.38 Algorithm testing\n",
    "# data = readcsv(\"magic04.txt\")\n",
    "\n",
    "I = map(Float64, data[:, 1:(end - 1)])  # A\n",
    "O = data[:, end]                        # B\n",
    "\n",
    "# A: take all the columns of the data matrix, aprot from the last one andconvert\n",
    "#    everything into a Float. Result = 10-dimArray of Float numbers\n",
    "# B: take only the lastcolumnof the data matrix.\n",
    "#    Result = 1-dim Array\n",
    "\n",
    "# Listing 2.5 Code for testingthe implementation of the kNN algorithm,\n",
    "# using the preloaded Magic dataset.\n",
    "N = length(O)                   # A\n",
    "n = round(Int64, N/2)           # B\n",
    "# R = randperm(N)\n",
    "R = [4, 5, 2, 7, 6, 1, 8, 3]    # C\n",
    "indX = R[1:n]                   # D\n",
    "X = I[indX, :]                  # E\n",
    "x = O[indX]                     # F\n",
    "indY = R[(n+1):end]             # G\n",
    "Y = I[indY, :]                  # E\n",
    "y = O[indY]\n",
    "# A: number of data pints in the whole dataset(which is equivalent to the lenght of array O)\n",
    "# B: the half of the above number\n",
    "# C: a random permutation of all the indexes(essential for sampling)\n",
    "# D: get some random indexes for the training set\n",
    "# E: input values for training and testing set respectively\n",
    "# F: target values for training and testing set respectively\n",
    "# G: some random indexes for the testing set\n",
    "\n",
    "z = apply_kNN(X, x, Y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "[23.8172 9.5728 … 10.449 116.737; 75.1362 30.9205 … 4.648 356.462; 31.6036 11.7235 … 6.3609 205.261; 120.513 76.9018 … 84.6874 408.317],\n",
       "\n",
       "Any[\"g\",\"g\",\"g\",\"h\"],\n",
       "[75.4455 47.5305 … 30.2987 256.517; 28.7967 16.0021 … 40.092 81.8828; 187.181 53.0014 … 52.731 272.317; 162.052 136.031 … 76.96 256.788])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, x, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gg\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p.39 Saving your workspace into a data file\n",
    "# Saving data into delimited files\n",
    "writedlm(\"/data/mydata.dat\", A, \";\")\n",
    "\n",
    "writecsv(\"/data/mydata.dat\", A)\n",
    "\n",
    "# Saving data into Native Julia format; other libraries are needed\n",
    "# Pkg.add(\"HDF5\")\n",
    "# Pkg.add(\"JLD\")\n",
    "using JLD\n",
    "f = open(\"mydata.jld\", \"w\")\n",
    "@write f A      # write variable A into a file f\n",
    "@write f b      # write variable b into a file f\n",
    "close(f)\n",
    "# Alternative way of writing into .jld fformat\n",
    "save(\"mydata.jld\", \"var_A\", A, \"var_B\", b)\n",
    "# if you wish to save all the variables in the workspace,\n",
    "save(\"mydata.jld\")\n",
    "# to retrive the data stored in a .jld file,\n",
    "D = load(\"mydata.jld\")\n",
    "# to access only a particular variable in a .jld file\n",
    "b = load(\"mydata.jld\", \"var_b\")\n",
    "# to access the variables stored in a .jld file partially\n",
    "f = jldopen(\"mydata.jld\", \"r\")\n",
    "dump(f, 20)     # reading the first 20 variables from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving data into text files\n",
    "f = open(\"/data/mydata.txt\", \"w\")\n",
    "write(f, SomeStringVariable)\n",
    "write(f, AnotherStringVariable)\n",
    "# ...\n",
    "close(f)\n",
    "# to save a string data to a data file which is already open\n",
    "A = [123, 34423.23, -322, 981238651928736918263]\n",
    "f = open(\"p43example.txt\", \"w\")\n",
    "for a in A\n",
    "        write(f, string(a, \"\\n\"))\n",
    "end\n",
    "close(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
